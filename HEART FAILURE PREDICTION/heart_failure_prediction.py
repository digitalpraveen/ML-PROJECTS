# -*- coding: utf-8 -*-
"""HEART_FAILURE_PREDICTION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mYHab2QKmFBsKxt7Rc8vCaBkuTtjBvsF
"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report,accuracy_score,confusion_matrix
from sklearn.preprocessing import StandardScaler

from sklearn.svm import SVC

from sklearn.linear_model import Perceptron

import plotly.graph_objs as go
from plotly.subplots import make_subplots
import plotly.express as px
import plotly.figure_factory as ff

heart_data=pd.read_csv("heart_failure_clinical_records.csv")
heart_data.head()

"""**Is Age and Sex an indicator for Deadth Event ?**"""

hist_data =[heart_data["age"].values]
group_labels = ['age']

fig = ff.create_distplot(hist_data, group_labels)
fig.update_layout(title_text='Age Distribution plot')

fig.show()

"""Age wise 40 to 80 the spread is High

Age less than 40 age and higher than 80 age people are very low
"""

fig = px.box(heart_data, x='sex', y='age', points="all")
fig.update_layout(
    title_text="Gender wise Age Spread - Male = 1 Female =0")
fig.show()

sns.pairplot(heart_data,vars=['time','ejection_fraction','serum_creatinine','age'],hue="DEATH_EVENT")

sns.countplot(heart_data["DEATH_EVENT"])

plt.figure(figsize=(30,13))
sns.heatmap(heart_data.corr(),annot=True)

"""**DATA MODELING**

**TRAIN TEST SPLIT**
"""

Features = ['time','ejection_fraction','serum_creatinine','age']
X = heart_data[Features]
Y = heart_data["DEATH_EVENT"]

X.head()

Y.head()

heart_data.dtypes

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2, random_state=2698)

accuracy_list = []

"""**SUPPORT VECTOR CLASSIFICATION**"""

h_data=SVC()
h_data.fit(X_train,Y_train)
h_data_pred= h_data.predict(X_test)
sv_clf_acc = accuracy_score(Y_test,h_data_pred)
accuracy_list.append(100* sv_clf_acc)

print( "Accuracy of SVC is : ", "{:.2f}%".format(100* sv_clf_acc))

cm = confusion_matrix(Y_test,h_data_pred)
sns.heatmap(cm,annot=True)

print(classification_report(Y_test,h_data_pred))

min_train=X_train.min()
min_train

"""**PERCEPTRON**"""

heart_data=pd.read_csv("heart_failure_clinical_records.csv")
heart_data.head()
Features = ['time','ejection_fraction','serum_creatinine','age']
X = heart_data[Features]
y = heart_data["DEATH_EVENT"]

def accuracy(y_true, y_pred):
    accuracy = np.sum(y_true == y_pred) / len(y_true)
    return accuracy


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)

p = Perceptron(max_iter=500, eta0=0.5, random_state=0)
p.fit(X_train, y_train)
predictions = p.predict(X_test)
print(predictions)

print("Perceptron classification accuracy", accuracy(y_test, predictions)*100)

plt.scatter(X_train.index,y_train.values)
plt.show()



"""**SELF ORGANISING MAPS**"""

h_data=pd.read_csv("heart_failure_clinical_records.csv")
h_data.head()

dataset=h_data.drop(['DEATH_EVENT'],axis=1)

dataset.head()

standard=StandardScaler()
cleanDataset=pd.DataFrame(standard.fit_transform(dataset))
cleanDataset.head()

pip install minisom

from minisom import MiniSom
from matplotlib.gridspec import GridSpec
som=MiniSom(10,10,12,sigma=0.25,neighborhood_function='gaussian')
som.train_random(cleanDataset.to_numpy(),30000)

target=h_data.DEATH_EVENT.astype('category').cat.codes
labels_map=som.labels_map(cleanDataset.to_numpy(),target)
label_names=np.unique(target)

target

labels_map

label_names

plt.figure(figsize=(10,10))
the_grid=GridSpec(10,10)
for position in labels_map.keys():
  label_fracs=[labels_map[position][1] for l in label_names]
  plt.subplot(the_grid[9-position[1],position[0]],aspect=1)
  patches,texts=plt.pie(label_fracs)
plt.legend(patches,label_names,bbox_to_anchor=(0,1.5),ncol=3)
plt.show

plt.figure(figsize=(10,10))
frequencies=np.zeros((10,10))
for position,values in som.win_map(cleanDataset.to_numpy()).items():
  frequencies[position[0],position[1]] = len(values)
plt.pcolor(frequencies,cmap='Blues')
plt.colorbar()
plt.show()

"""**LEARNING VECTOR QUANTIZATION**"""

pip install neupy

from neupy import algorithms, utils


utils.reproducible()


def plot_scattermatrix(data, target):
    df = pd.DataFrame(data)
    df['target'] = target
    return sns.pairplot(df, hue='target', diag_kind='hist')


if __name__ == '__main__':
    dataset = pd.read_csv("heart_failure_clinical_records.csv")
    data, target = h_data.drop(['DEATH_EVENT'],axis=1), dataset.DEATH_EVENT
    

    lvqnet = algorithms.LVQ(
        # number of features
        n_inputs=11,

        # number of data points that we want
        # to have at the end
        n_subclasses=100,

        # number of classes
        n_classes=2,

        verbose=True,
        show_epoch=20,

        step=0.001,
        n_updates_to_stepdrop=150 * 100,
    )
    lvqnet.train(data, target, epochs=100)
    
    plot_scattermatrix(data, target)
    plot_scattermatrix(data=lvqnet.weight, target=lvqnet.subclass_to_class)
    plt.show()